{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPW6bTsk1c6DdZVd9STeucW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pk2971/computational-gender-analysis/blob/main/notebooks/Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpXToVcgxGga"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu --no-cache\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pfYw1F0GX1l",
        "outputId": "ae0fa336-99bf-4a53-b0e1-d8e8f9d6aec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m161.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/debates.zip'\n",
        "# Clean and parse XML text\n",
        "def extract_text_from_speech(xml_bytes):\n",
        "    try:\n",
        "        root = ET.fromstring(xml_bytes)\n",
        "        return ' '.join([p.text or '' for p in root.findall('.//speech//p')])\n",
        "    except ET.ParseError:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "6WRkGVuxBZ8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Chunk and embed\n",
        "def chunk_text(text, chunk_size=1000, overlap=200):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), chunk_size - overlap):\n",
        "        chunk = \" \".join(words[i:i + chunk_size])\n",
        "        if chunk:\n",
        "            chunks.append(chunk)\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "KWRtPriWGWCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_faiss_index(chunks, embedder):\n",
        "    embeddings = embedder.encode(chunks, convert_to_numpy=True)\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "    index.add(embeddings)\n",
        "    return index, embeddings"
      ],
      "metadata": {
        "id": "u4IhU5KQGzDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Retrieval\n",
        "def retrieve_relevant_chunks(question, chunks, embedder, index, top_k=5):\n",
        "    q_emb = embedder.encode([question], convert_to_numpy=True)\n",
        "    D, I = index.search(q_emb, top_k)\n",
        "    return [chunks[i] for i in I[0]]"
      ],
      "metadata": {
        "id": "qMwslOInG2Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Summarization/QA\n",
        "def summarize_with_model(context, question, model_name=\"google/flan-t5-small\"):\n",
        "    summarizer = pipeline(\"summarization\", model=model_name)\n",
        "    input_text = question + \"\\n\" + context\n",
        "    summary = summarizer(input_text, max_length=150, min_length=30, do_sample=False)\n",
        "    return summary[0]['summary_text']"
      ],
      "metadata": {
        "id": "CMqiBJMKG5Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function\n",
        "def rag_summarize(zip_path, year_input, question, extra_stopwords=[]):\n",
        "    # Collect documents\n",
        "    if isinstance(year_input, int):\n",
        "        start_year, end_year = year_input, year_input\n",
        "    else:\n",
        "        start_year, end_year = year_input\n",
        "    year_docs = collect_documents_by_year(zip_path, start_year, end_year)\n",
        "    text = \" \".join(year_docs.values())\n",
        "    # Chunk and embed\n",
        "    chunks = chunk_text(text)\n",
        "    embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    index, _ = build_faiss_index(chunks, embedder)\n",
        "    # Retrieve\n",
        "    relevant_chunks = retrieve_relevant_chunks(question, chunks, embedder, index, top_k=5)\n",
        "    context = \" \".join(relevant_chunks)\n",
        "    # Summarize/QA\n",
        "    answer = summarize_with_model(context, question)\n",
        "    return answer"
      ],
      "metadata": {
        "id": "sR5Cj7x8G7zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage:\n",
        "# answer = rag_summarize('/content/drive/MyDrive/debates.zip', (1919, 1920), \"What were the main concerns about war in parliament?\")\n",
        "# print(answer)\n",
        "abcd"
      ],
      "metadata": {
        "id": "u1YkXkqrG90T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}